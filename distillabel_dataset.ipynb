{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ichikomunikation/temporaryrepo/blob/main/distillabel_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d788a7c-0740-4308-bee4-9c88ca1fb2cd",
      "metadata": {
        "id": "5d788a7c-0740-4308-bee4-9c88ca1fb2cd"
      },
      "outputs": [],
      "source": [
        "!pip install \"distilabel[openai]\" --upgrade\n",
        "!pip install mistralai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2ef55286-ccb6-49ea-978b-e93055006bda",
      "metadata": {
        "id": "2ef55286-ccb6-49ea-978b-e93055006bda"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from distilabel.llms import OpenAILLM\n",
        "from distilabel.llms import MistralLLM\n",
        "from distilabel.llms import TogetherLLM\n",
        "from distilabel.pipeline import Pipeline\n",
        "from distilabel.steps import LoadDataFromDicts\n",
        "from distilabel.steps.tasks import TextGeneration\n",
        "from distilabel.steps.tasks.self_instruct import SelfInstruct\n",
        "from distilabel.steps.tasks.evol_instruct.base import EvolInstruct\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "from distilabel.llms import LlamaCppLLM\n",
        "from pydantic import BaseModel, StringConstraints, conint\n",
        "from typing_extensions import Annotated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2ae6e133-a896-4036-a48a-6897f59c0cf7",
      "metadata": {
        "id": "2ae6e133-a896-4036-a48a-6897f59c0cf7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "sample_data = [\n",
        "    \"Our records show you overpaid for (a product or service). Kindly supply your bank routing and account number to receive your refund.\",\n",
        "    \"You won a lottery of $4000. Please click on provide link http://random.to to receive your fund.\",\n",
        "    \"URGENT! Your Bank Account Will Be Closed! Click here to verify your informations http://bit.ly/3xYz2d\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_scam =  \"scammer : Hello, thank you for reaching out to our esteemed organization, Charity for Humanity. I am Laura, your dedicated charity representative. We are working diligently to provide assistance to vulnerable people in your area. , user: Hello Laura, how can I help?, scammer: Great to hear from you! We need your support to provide essential aid such as food and medicine to the needy in your local community. As a valued donor, you can make a significant difference by contributing $250., user: Is this a legitimate charity?, scammer: Absolutely! We have been operating since 2005, helping thousands of people in need. Our work is endorsed by renowned philanthropists and celebrities. Your contribution will help provide much-needed relief to the less fortunate. , scammer: Once you make your tax-deductible donation, we will promptly prepare a personalized certificate acknowledging your generosity to be displayed in your home or office. , user: Okay, how do I make the payment?\"\n",
        "\n",
        "# Open the file in read mode\n",
        "with open('conversations.txt', 'r') as file:\n",
        "    # Read the entire content of the file\n",
        "    content = file.read()\n",
        "\n",
        "# Use regex to find all strings enclosed in double quotes\n",
        "strings = re.findall(r'\"(.*?)\"', content)\n",
        "\n",
        "conversation_data = strings\n",
        "print(len(conversation_data))"
      ],
      "metadata": {
        "id": "5JysCIZtEof9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895d922c-3ddf-497e-8b1c-d672ced7016f"
      },
      "id": "5JysCIZtEof9",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b03ab724-c8b4-4737-92b7-847645508c02",
      "metadata": {
        "id": "b03ab724-c8b4-4737-92b7-847645508c02"
      },
      "outputs": [],
      "source": [
        "application_decription = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "62fd154a-701c-401a-96c4-d79f20ea0e1d",
      "metadata": {
        "id": "62fd154a-701c-401a-96c4-d79f20ea0e1d"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"cognitivecomputations/dolphin-2.5-mixtral-8x7b\"\n",
        "LLM_API_KEY = \"6c011f7e603f528a120134c78d5c6a1f643df1f44553cc3413ff4c984466f83c\"\n",
        "TEMPERATURE = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4ccdaeb5-8671-428e-8894-a816b297b130",
      "metadata": {
        "id": "4ccdaeb5-8671-428e-8894-a816b297b130"
      },
      "outputs": [],
      "source": [
        "with Pipeline(\n",
        "    name = \"scam_data_generation_pipeline\",\n",
        "    description = \"A pipline for generating scam dataset\") as pipeline:\n",
        "    load_dataset = LoadDataFromDicts(\n",
        "                    name = \"load_data\",\n",
        "                    data = [\n",
        "                        {\n",
        "                            \"system_prompt\": \"generate 5 texts which are similar to this in english language in JSON format.\",\n",
        "                            \"instruction\": sample\n",
        "                        } for sample in sample_data\n",
        "                    ],\n",
        "                    batch_size = 1\n",
        "                )\n",
        "\n",
        "    text_generation = TextGeneration(\n",
        "                        name = \"scam_dataset_generation\",\n",
        "                        llm=TogetherLLM(model = MODEL_ID, api_key = LLM_API_KEY))\n",
        "\n",
        "    load_dataset.connect(text_generation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8091d09-0f8a-43ab-8fdb-49659d2a58da",
      "metadata": {
        "id": "f8091d09-0f8a-43ab-8fdb-49659d2a58da"
      },
      "outputs": [],
      "source": [
        "scam_dataset = pipeline.run(\n",
        "    parameters = {\n",
        "        text_generation.name: {\n",
        "            \"llm\": {\n",
        "                \"generation_kwargs\": {\n",
        "                    \"temperature\": TEMPERATURE,\n",
        "                    \"max_new_tokens\": 512,\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b70841f-94e9-4fd5-bd8b-8e18a3fc06e6",
      "metadata": {
        "id": "3b70841f-94e9-4fd5-bd8b-8e18a3fc06e6"
      },
      "outputs": [],
      "source": [
        "scam_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scam_dataset['default']['train'][0]"
      ],
      "metadata": {
        "id": "iRid01IYpVrU"
      },
      "id": "iRid01IYpVrU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self_instruct = SelfInstruct(\n",
        "    name=\"text-generation\",\n",
        "    num_instructions=8,\n",
        "    application_description=\"scam message generator\",\n",
        "    input_batch_size=8,\n",
        "    llm=TogetherLLM(\n",
        "        model=MODEL_ID,\n",
        "        api_key=LLM_API_KEY\n",
        "    ),\n",
        "    pipeline=Pipeline(name=\"self-instruct-pipeline\")\n",
        ")\n",
        "\n",
        "# remember to call .load() if testing outside of a Pipeline context\n",
        "self_instruct.load()"
      ],
      "metadata": {
        "id": "qWWCfMp6ue36"
      },
      "id": "qWWCfMp6ue36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = next(\n",
        "    self_instruct.process(\n",
        "        [\n",
        "            {\n",
        "                \"input\": sample_data[1],\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "i6AkF5bwLWec"
      },
      "id": "i6AkF5bwLWec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(json.dumps(result, indent=2))"
      ],
      "metadata": {
        "id": "-NAQqmPULgi7"
      },
      "id": "-NAQqmPULgi7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('complete_scam_augmented_data.txt', 'a') as output:\n",
        "  for data_idx in range (0, len(conversation_data)):\n",
        "    for evol in range (0, 10):\n",
        "      evol_instruct = EvolInstruct(\n",
        "          name=\"evol-instruct\",\n",
        "          num_evolutions=2,\n",
        "          store_evolutions=True,\n",
        "          input_batch_size=8,\n",
        "          llm=TogetherLLM(\n",
        "              model=MODEL_ID,\n",
        "              api_key=LLM_API_KEY,\n",
        "              generation_kwargs = {\n",
        "                \"max_new_tokens\": 1024,\n",
        "              }\n",
        "          ),\n",
        "          pipeline=Pipeline(name=\"evol-instruct-pipeline\")\n",
        "      )\n",
        "\n",
        "      # remember to call .load() if testing outside of a Pipeline context\n",
        "      evol_instruct.load()\n",
        "\n",
        "      result = next(\n",
        "        evol_instruct.process(\n",
        "            [\n",
        "                {\n",
        "                    \"instruction\": conversation_data[data_idx]\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "      )\n",
        "\n",
        "      output.write(json.dumps(result[0]['evolved_instructions'][0], indent=2) + \"\\n\" + \"\\n\")\n",
        "      # print(json.dumps(result[0]['evolved_instructions'][0], indent=2))\n"
      ],
      "metadata": {
        "id": "Y0cMKg5UL33T"
      },
      "id": "Y0cMKg5UL33T",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = next(\n",
        "    evol_instruct.process(\n",
        "        [\n",
        "            {\n",
        "                \"instruction\": \"scammer: Hey there! I recently came across your profile and would like to connect with you about a financial opportunity, user: What kind of opportunity are you talking about?\"\n",
        "            },\n",
        "            {\n",
        "                \"instruction\": \"scammer: Yes, I was the winner of a big jackpot in the recent lottery! I feel so lucky Yes, I won big time in the recent lottery! I must be one of the luckiest people on Earth!, victim: Really? Congratulations, that's amazing news! How much did you win?, scammer: Thank you. I won over $5 million dollars! However, I need to deposit $10,000 to unlock my winnings., victim: Wow, that's a lot of money for unlocking! But, I understand. How can I assist you to complete this process?, scammer: Please send the $10,000 to this secure bank account. Once the transaction is completed, I will receive my winnings., victim: Okay, here's my bank account number for the transfer, scammer: That is perfect, thank you. Upon receiving the transaction we will process the withdrawal of your winnings and proceed with the transfer to your account.\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "QvlePJV_GYmf"
      },
      "id": "QvlePJV_GYmf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(result[1]['evolved_instructions'], indent=2))"
      ],
      "metadata": {
        "id": "HIOSJhCeGY7Q"
      },
      "id": "HIOSJhCeGY7Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script for Data Augmentation"
      ],
      "metadata": {
        "id": "EvTb64Rr7uIT"
      },
      "id": "EvTb64Rr7uIT"
    },
    {
      "cell_type": "code",
      "source": [
        "\"Bank Representative: Dear customer, we noticed that your KYC details are outdated. To ensure the security of your account, we recommend updating your KYC details within the next few days. You can do this by visiting our official website or the nearest branch., User: Oh! I didn’t realize my KYC details were outdated. How can I update them?, Bank Representative: No worries, Sir. You can easily update your KYC details by logging into your online banking account through our official website. Please make sure you are on our secure website by typing the URL directly into your browser, or you can visit your nearest branch for assistance., User: “The link you provided isn’t working., Bank Representative: I apologize for any inconvenience, Sir. Please avoid using any links from unknown sources. Instead, visit our official website or contact our customer service for help. We’ll be happy to guide you through the process., User: Alright, I’ll do that. Thank you for the assistance., Bank Representative: You’re welcome! If you have any further questions or need additional support, please don’t hesitate to contact us. Your security is our top priority.\""
      ],
      "metadata": {
        "id": "st_kVz5l89wv"
      },
      "id": "st_kVz5l89wv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment"
      ],
      "metadata": {
        "id": "C0dm2shr9A4T"
      },
      "id": "C0dm2shr9A4T"
    },
    {
      "cell_type": "code",
      "source": [
        "class ScamType(str, Enum):\n",
        "    phishing = \"phishing scam\"\n",
        "    lottery = \"lottery scam\"\n",
        "    charity = \"charity scam\"\n",
        "    investment = \"investment scam\"\n",
        "    email = \"email scam\"\n",
        "    romance = \"romance scam\"\n",
        "\n",
        "# class Character(BaseModel):\n",
        "#     name: Annotated[str, StringConstraints(max_length=30)]\n",
        "#     scamType: ScamType\n",
        "\n",
        "with Pipeline(\"Scam-generation\") as pipeline:\n",
        "    system_prompt = (\n",
        "        \"You are a scam conservation generator. You have seen thousands of conversations between scammers and normal people.\"\n",
        "        \" Please return a JSON object with a conversation between scammer and user. All conversations should have same format\"\n",
        "    )\n",
        "\n",
        "    load_dataset = LoadDataFromDicts(\n",
        "        name=\"load_instructions\",\n",
        "        data=[\n",
        "            {\n",
        "                \"system_prompt\": system_prompt,\n",
        "                \"instruction\": f\"Give me a scam conversation for {scam}\",\n",
        "            }\n",
        "            for scam in [\"phishing scam\", \"lottery scam\", \"charity scam\", \"investmant scam\", \"email scam\", \"romance scam\"]\n",
        "        ],\n",
        "    )\n",
        "    # llm = LlamaCppLLM(\n",
        "    #     model=MODEL_ID,  # type: ignore\n",
        "    #     n_gpu_layers=-1,\n",
        "    #     n_ctx=1024,\n",
        "    #     structured_output={\"format\": \"json\", \"schema\": Character},\n",
        "    # )\n",
        "    # Change to vLLM as such:\n",
        "    # llm = vLLM(\n",
        "    #     model=\"teknium/OpenHermes-2.5-Mistral-7B\",\n",
        "    #     extra_kwargs={\"tensor_parallel_size\": 1},\n",
        "    #     structured_output={\"format\": \"json\", \"schema\": Character},\n",
        "    # )\n",
        "\n",
        "    llm = TogetherLLM(\n",
        "        model=MODEL_ID,\n",
        "        api_key=LLM_API_KEY,\n",
        "    )\n",
        "\n",
        "    text_generation = TextGeneration(\n",
        "        name=\"scam_generation\",\n",
        "        llm=llm,\n",
        "        input_batch_size=8,\n",
        "        output_mappings={\"model_name\": \"generation_model\"},\n",
        "    )\n",
        "    load_dataset >> text_generation\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    distiset = pipeline.run(\n",
        "        parameters={\n",
        "            text_generation.name: {\n",
        "                \"llm\": {\"generation_kwargs\": {\"max_new_tokens\": 256}}\n",
        "            }\n",
        "        },\n",
        "        use_cache=False,\n",
        "    )\n",
        "    for num, character in enumerate(distiset[\"default\"][\"train\"][\"generation\"]):\n",
        "        print(f\"Dataset: {num}\")\n",
        "        print(character)"
      ],
      "metadata": {
        "id": "jnnH-0nrIcUb"
      },
      "id": "jnnH-0nrIcUb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YmfWYS1zHX68"
      },
      "id": "YmfWYS1zHX68",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}